{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# plot 4 images as gray scale\n",
    "#plt.subplot(221)\n",
    "#plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "#plt.subplot(222)\n",
    "#plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "#plt.subplot(223)\n",
    "#plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "#plt.subplot(224)\n",
    "#plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "#plt.show()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "seed = 11\n",
    "print(numpy.random.seed(seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 256s - loss: 0.2395 - acc: 0.9330 - val_loss: 0.0829 - val_acc: 0.9752\n",
      "Epoch 2/10\n",
      " - 242s - loss: 0.0753 - acc: 0.9780 - val_loss: 0.0530 - val_acc: 0.9829\n",
      "Epoch 3/10\n",
      " - 237s - loss: 0.0530 - acc: 0.9840 - val_loss: 0.0437 - val_acc: 0.9853\n",
      "Epoch 4/10\n",
      " - 239s - loss: 0.0408 - acc: 0.9873 - val_loss: 0.0370 - val_acc: 0.9882\n",
      "Epoch 5/10\n",
      " - 244s - loss: 0.0332 - acc: 0.9897 - val_loss: 0.0370 - val_acc: 0.9874\n",
      "Epoch 6/10\n",
      " - 246s - loss: 0.0292 - acc: 0.9906 - val_loss: 0.0405 - val_acc: 0.9869\n",
      "Epoch 7/10\n",
      " - 253s - loss: 0.0225 - acc: 0.9931 - val_loss: 0.0319 - val_acc: 0.9895\n",
      "Epoch 8/10\n",
      " - 240s - loss: 0.0198 - acc: 0.9936 - val_loss: 0.0341 - val_acc: 0.9885\n",
      "Epoch 9/10\n",
      " - 249s - loss: 0.0172 - acc: 0.9947 - val_loss: 0.0336 - val_acc: 0.9900\n",
      "Epoch 10/10\n",
      " - 239s - loss: 0.0159 - acc: 0.9950 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "CNN Error: 1.23%\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
